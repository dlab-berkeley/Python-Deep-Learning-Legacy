{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the Input Data\n",
    "\n",
    "1. Why do we use split our data into train/validation/test?\n",
    "2. What is the shape of our input data partitions?\n",
    "3. What is the type of the data?\n",
    "\n",
    "**BONUS:**\n",
    "\n",
    "4. What is the distribution of the target classes within the data, is it balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Why do we use split our data into train/validation/test?\n",
    "\n",
    "# We need to train our model and avoid overfitting.\n",
    "\n",
    "# We use the training set to fit the model.\n",
    "# We use the validation set to tune the hyperparameters of our model.\n",
    "# We use the holdout test set to determine our final performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 What is the shape of our input data partitions?\n",
    "\n",
    "# The training set contains 5000 examples\n",
    "# The validation set contains 1000 examples \n",
    "# The test set contains 1000 examples\n",
    "# The X are 3-dimensional\n",
    "# The y are 1 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "[type(partition) for partition in [x_train, y_train, x_val, y_val, x_test, y_test]]\n",
    "# All are numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS 1.4\n",
    "\n",
    "# Simply plot the histogram of each y in a different cell, for example\n",
    "# plt.hist(y_train)\n",
    "# plt.title('Train Class Distribution');\n",
    "# repeat for y_val and y_test\n",
    " \n",
    "# or make subplots\n",
    "def plot_target_distributions(targets, titles):\n",
    "    \"\"\"\n",
    "    Returns the distribution of target classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(3,1, figsize = (10,10))\n",
    "    \n",
    "    for ax, target, title in zip(axes, targets, titles):\n",
    "        ax.hist(target) \n",
    "        ax.set_title(f\"{title} Class Distribution\")\n",
    "    \n",
    "    return plt.show()\n",
    "\n",
    "plot_target_distributions([y_train, y_val, y_test], [\"Train\", \"Validation\", \"Test\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Build your own neural network\n",
    "\n",
    "1. Build and compile your own neural network in an object called `my_network`. Feel free to choose your own:\n",
    "    - Architecture\n",
    "    - Activation Function\n",
    "    - Epochs\n",
    "    \n",
    "2. Train your model, saving the results to an object called `history_my_network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "# An example network with: 3 dense layers, each with 512 neurons and a dropout of 0.3\n",
    "\n",
    "my_network = Sequential()\n",
    "my_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "my_network.add(Dropout(0.3))\n",
    "my_network.add(Dense(512, activation= \"relu\"))\n",
    "my_network.add(Dropout(0.3))\n",
    "my_network.add(Dense(512, activation= \"relu\"))\n",
    "my_network.add(Dropout(0.3))\n",
    "my_network.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "my_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "# Train model for 20 epochs with batch size of 128\n",
    "history_my_network = my_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=20, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Evaluate your own model\n",
    "\n",
    "Use your own model from challenge 2 to evaluate its general performance.\n",
    "\n",
    "1. Visualize the training and validation accuracy over each epoch.\n",
    "2. Print the accuracy of your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 \n",
    "plot_epoch_accuracy(history_my_network.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2\n",
    "get_model_accuracy(my_network, x_test_trans, y_test_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Save your own model\n",
    "\n",
    "Save your own model `my_network` in the same directory we saved our other models in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "save_models(my_network, \"my_network\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
