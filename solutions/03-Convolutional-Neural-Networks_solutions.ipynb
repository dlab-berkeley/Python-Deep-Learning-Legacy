{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(subset = True):\n",
    "    \"\"\"\n",
    "    Loads a training, validation, and test set of CIFAR10 images.\n",
    "    \n",
    "    When subset=TRUE:\n",
    "    Returns only a subset of the mnist dataset.\n",
    "    Especially important to use if you are on datahub and only have 1-2GB of memory.\n",
    "    \"\"\"\n",
    "    if subset:\n",
    "        N_TRAIN = 8000\n",
    "        N_VALIDATION = 2000\n",
    "        N_TEST = 2000\n",
    "    else:\n",
    "        N_TRAIN = 40000\n",
    "        N_VALIDATION = 10000\n",
    "        N_TEST = 10000\n",
    "    \n",
    "    (x_train_and_val, y_train_and_val), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    x_train = x_train_and_val[:N_TRAIN,:,:]\n",
    "    y_train = y_train_and_val[:N_TRAIN]\n",
    "    \n",
    "    x_val = x_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION,:,:]\n",
    "    y_val = y_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION]\n",
    "    \n",
    "    x_test = x_test[:N_TEST]\n",
    "    y_test = y_test[:N_TEST]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = load_cifar10()\n",
    "\n",
    "def three_dim_transform(x_data, y_data):\n",
    "    \"\"\"\n",
    "    Transforms image data:\n",
    "        - Scales pixel values between [0,1]\n",
    "    Transforms target data (ydata):\n",
    "        - Formats targets as one hot encoded columns\n",
    "    \"\"\"\n",
    "    \n",
    "    x = {}\n",
    "    for name, partition in zip([\"x_train\", \"x_val\", \"x_test\"],x_data):\n",
    "        scaled = partition.astype('float32') / 255\n",
    "        x[name] = scaled\n",
    "    \n",
    "    y = {}\n",
    "    for name, partition in zip([\"y_train\", \"y_val\", \"y_test\"],y_data):\n",
    "        y[name] = to_categorical(partition)\n",
    "    \n",
    "    return x['x_train'], y['y_train'], x['x_val'], y['y_val'], x['x_test'], y['y_test']\n",
    "\n",
    "x_train_trans, y_train_trans, x_val_trans, y_val_trans, x_test_trans, y_test_trans = three_dim_transform([x_train, x_val, x_test],\n",
    "                                                                                                    [y_train, y_val, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa6f63",
   "metadata": {},
   "source": [
    "## Challenge 1: Translate Classes\n",
    "\n",
    "Create a function `translate_class()` that uses the correct class name for the target classes (truck, horse, etc..).\n",
    "- Use the [keras CIFAR10 documentation](https://keras.io/api/datasets/cifar10/) as a guide to know how the classes are labeled.\n",
    "- The function should take a class index [0-9]\n",
    "- The function should return the correct corresponding CIFAR10 class category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_class(y):\n",
    "    \"\"\"\n",
    "    Takes a class index [0-9] and returns the CIFAR10 class category.\n",
    "    \"\"\"\n",
    "    # Create a list of categories\n",
    "    categories = [\"airplane\", \n",
    "                 \"automobile\",\n",
    "                 \"bird\",\n",
    "                 \"cat\",\n",
    "                 \"deer\",\n",
    "                 \"dog\",\n",
    "                 \"frog\",\n",
    "                 \"horse\",\n",
    "                 \"ship\",\n",
    "                 \"truck\"]\n",
    "    \n",
    "    return categories[y]\n",
    "    \n",
    "    \n",
    "def translate_classes_fancy(y):\n",
    "    \"\"\"\n",
    "    Use a key-value paired dictionary to translate target class\n",
    "    \"\"\"\n",
    "    # Create a list of categories\n",
    "    categories = [\"airplane\", \n",
    "                 \"automobile\",\n",
    "                 \"bird\",\n",
    "                 \"cat\",\n",
    "                 \"deer\",\n",
    "                 \"dog\",\n",
    "                 \"frog\",\n",
    "                 \"horse\",\n",
    "                 \"ship\",\n",
    "                 \"truck\"]\n",
    "    \n",
    "    # Use a dictionary comprehesion to attach class number to category\n",
    "    category_dict = {key : value for key, value in zip(list(range(10)), categories)}\n",
    "    \n",
    "    return category_dict[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4d69c",
   "metadata": {},
   "source": [
    "## Challenge 2: Plotting Image Classes\n",
    "\n",
    "Create a new function `my_imageplotter()` that reuses code from our `plot_images()` function and incorporates the `translate_class()` function to give us the correct class titles in our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_imageplotter(x, y, random=False):\n",
    "    \"\"\"\n",
    "    Plots 25 images from x data with titles set as y.\n",
    "    Set random=True if you want random images rather than the first 25.\n",
    "    \"\"\"\n",
    "    \n",
    "    if random:\n",
    "        indices = np.random.choice(range(y.shape[0]), 25, replace=False)\n",
    "    \n",
    "    else:\n",
    "        indices = np.array(range(25))\n",
    "    \n",
    "    fig, axes = plt.subplots(5,5, figsize = (15,15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for ax, index in zip(axes, indices):\n",
    "        # NEW LINE HERE\n",
    "        title = translate_class(y[index][0])\n",
    "        ax.imshow(x[index])\n",
    "        ax.set_title(f\"Class: {title}\", size=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f551f",
   "metadata": {},
   "source": [
    "## Challenge 3: Create a Convolutional Neural Network\n",
    "\n",
    "1. Initialize a Convolutional Neural Network called `my_convnet` with the following architecture:\n",
    "    * Conv2D layer with 32 3x3 filters and relu activation function\n",
    "    * Maxpooling layer 2x2\n",
    "    * Conv2D layer with 64 3x3 filters and relu activation function\n",
    "    * Maxpooling layer 2x2\n",
    "    * Conv2D layer with 128 3x3 filters and relu activation function\n",
    "    * Maxpooling layer wtih a pool size of 2x2\n",
    "    * A flattening layer\n",
    "    * A dense layer with 512 neurons  and relu activation function\n",
    "    * An output layer with the number of classes and softmax activation function\n",
    "\n",
    "2. Compile with the model with:\n",
    "    * rmsprop optimizer\n",
    "    * categorical crossentropy loss\n",
    "    * accuracy metric\n",
    "\n",
    "3. Train the network for 20 epochs.\n",
    "\n",
    "4. Plot the training and validation accuracy through each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Initialize a Convolutional Neural Network called `my_convnet`\n",
    "my_convnet = models.Sequential()\n",
    "my_convnet.add(layers.Conv2D(32, (3,3), activation= \"relu\", input_shape = (32, 32, 3)))\n",
    "my_convnet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "my_convnet.add(layers.Conv2D(64, (3,3), activation= \"relu\"))\n",
    "my_convnet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "my_convnet.add(layers.Conv2D(128, (3,3), activation= \"relu\"))\n",
    "my_convnet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten for dense layers\n",
    "my_convnet.add(layers.Flatten())\n",
    "my_convnet.add(layers.Dense(512, activation= \"relu\"))\n",
    "my_convnet.add(layers.Dense(10, activation= \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40911e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Compile model\n",
    "my_convnet.compile(optimizer= \"rmsprop\",\n",
    "                   loss= \"categorical_crossentropy\",\n",
    "                   metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37491775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Train the network for 20 epochs\n",
    "my_convnet_history = my_convnet.fit(x_train_trans,\n",
    "                             y_train_trans,\n",
    "                             epochs=20,\n",
    "                             batch_size = 64,\n",
    "                             validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1497fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_accuracy(history_dict):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy of a neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, color = 'navy', alpha = 0.8, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, color = 'green', label='Validation Accuracy')\n",
    "    plt.title('Training and validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Plot accuracy through epochs\n",
    "plot_epoch_accuracy(my_convnet_history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
