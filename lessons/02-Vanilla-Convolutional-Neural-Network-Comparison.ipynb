{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a87e8f0",
   "metadata": {},
   "source": [
    "# Comparing Performance of Vanilla and Convolutional Neural Networks\n",
    "\n",
    "**Time**\n",
    "- Teaching: 15 minutes\n",
    "\n",
    "**Questions**\n",
    "- \"How do vanilla neural networks compare to convolutional neural networks?\"\n",
    "\n",
    "* * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e673336",
   "metadata": {},
   "source": [
    "The neural networks we have created so far are known as *vanilla neural networks*. \n",
    "\n",
    "These have many great usecases, but for problems in computer vision, we often use a different architecture called covolutional neural networks.\n",
    "\n",
    "We will review the the details of how the work in our slides tomorrow, but for today, let's just compare their efficacy to vanilla neural nets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de327f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(subset=True):\n",
    "    \"\"\"\n",
    "    Returns the MNIST dataset as a tuple:\n",
    "    (x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    \n",
    "    When subset=TRUE:\n",
    "    Returns only a subset of the mnist dataset.\n",
    "    Especially important to use if you are on datahub and only have 1-2GB of memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    if subset:\n",
    "        N_TRAIN = 5000\n",
    "        N_VALIDATION = 1000\n",
    "        N_TEST = 1000\n",
    "    else:\n",
    "        N_TRAIN = 48000\n",
    "        N_VALIDATION = 12000\n",
    "        N_TEST = 10000\n",
    "    \n",
    "    (x_train_and_val, y_train_and_val), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train_and_val[:N_TRAIN,:,:]\n",
    "    y_train = y_train_and_val[:N_TRAIN]\n",
    "    \n",
    "    x_val = x_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION,:,:]\n",
    "    y_val = y_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION]\n",
    "    \n",
    "    x_test = x_test[:N_TEST]\n",
    "    y_test = y_test[:N_TEST]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ec69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "convnet.add(MaxPooling2D((2, 2)))\n",
    "convnet.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "convnet.add(MaxPooling2D((2, 2)))\n",
    "convnet.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(64, activation='relu'))\n",
    "convnet.add(Dense(10, activation='softmax'))\n",
    "\n",
    "convnet.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba990a2",
   "metadata": {},
   "source": [
    "Note that convolutional neural networks don't need our data flattened, in fact they work well on multidimensional input data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e481e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = convnet.fit(x_train_2d,\n",
    "                      y_train_trans, \n",
    "                      epochs=10,\n",
    "                      batch_size=128,\n",
    "                      bvalidation_data=(x_val_2d, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_accuracy(history_dict):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy of a neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, color = 'navy', alpha = 0.8, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, color = 'green', label='Validation Accuracy')\n",
    "    plt.title('Training and validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_convnet.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbba5a7",
   "metadata": {},
   "source": [
    "So how well does our CNN perform on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_accuracy(convnet,x_test_2d, y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c477ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wrong_predictions(convnet, x_test_2d, y_test_trans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
