{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d434da15",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "**Time**\n",
    "- Teaching: 1.45 hours\n",
    "- Challenges: 30 minutes\n",
    "\n",
    "**Questions**\n",
    "- \"What is CIFAR10 and how does the modeling process and challenges differ from MNIST?\"\n",
    "- \"How do convolutional neural networks differ from vanilla neural networks?\"\n",
    "- \"How do we write python code to develop convolutional neural networks?\"\n",
    "- \"What options do we have to train large models if my personal machine can't handle it?\"\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "- \"Understand the process of data preprocessing for deep learning.\"\n",
    "- \"Build python functions that help us process and visualize our data.\"\n",
    "- \"Take a peek at the machinery underlying convolutional neural networks.\"\n",
    "- \"Understand the hardware constrains in deep learning.\"\n",
    "\n",
    "* * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b2889",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "For this notebook, instead of importing only specific functions, we will import some modules that contain functions.\n",
    "\n",
    "**Old way:**\n",
    "\n",
    "`from keras.layers import Dense`\n",
    "\n",
    "`model.add(Dense(...))`\n",
    "\n",
    "**New way:**\n",
    "\n",
    "`from keras import layers`\n",
    "\n",
    "`model.add(layers.Dense(...))`\n",
    "\n",
    "But why change it up? I had trouble myself in the past understanding the way modules work, so code would break due simply to the way imports were done. Let's avoid that by getting comfortable with python modules!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1358987",
   "metadata": {},
   "source": [
    "### CIFAR10\n",
    "\n",
    "So we get sidetracked at work and we want to instead build a classifier for animals and vehicles!\n",
    "\n",
    "We shop around and find an interesting image dataset called [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "This dataset consists of:\n",
    "- 60,000 total images\n",
    "- 10 classes (6,000 images per class)\n",
    "\n",
    "Example images of each class are shown below:\n",
    "\n",
    "![CIFAR10 classes](https://maet3608.github.io/nuts-ml/_images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b0fa1",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4074f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(subset = True):\n",
    "    \"\"\"\n",
    "    Loads a training, validation, and test set of CIFAR10 images.\n",
    "    \n",
    "    When subset=TRUE:\n",
    "    Returns only a subset of the mnist dataset.\n",
    "    Especially important to use if you are on datahub and only have 1-2GB of memory.\n",
    "    \"\"\"\n",
    "    if subset:\n",
    "        N_TRAIN = 8000\n",
    "        N_VALIDATION = 2000\n",
    "        N_TEST = 2000\n",
    "    else:\n",
    "        N_TRAIN = 40000\n",
    "        N_VALIDATION = 10000\n",
    "        N_TEST = 10000\n",
    "    \n",
    "    (x_train_and_val, y_train_and_val), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    x_train = x_train_and_val[:N_TRAIN,:,:]\n",
    "    y_train = y_train_and_val[:N_TRAIN]\n",
    "    \n",
    "    x_val = x_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION,:,:]\n",
    "    y_val = y_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION]\n",
    "    \n",
    "    x_test = x_test[:N_TEST]\n",
    "    y_test = y_test[:N_TEST]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf7c22",
   "metadata": {},
   "source": [
    "### Input Data Due Dillegence\n",
    "\n",
    "We will borrow some of our previous functions in order to get a feel for CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9206452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(data):\n",
    "    \"\"\"\n",
    "    Takes a list of our data partitions and returns the shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, data_partition in enumerate(data):\n",
    "        if i == 0:\n",
    "            print(\"Training Data\")\n",
    "        elif i == 2:\n",
    "            print()\n",
    "            print(\"Validation Data\")\n",
    "        elif i == 4:\n",
    "            print()\n",
    "            print(\"Testing Data\")\n",
    "\n",
    "        print(f\"Shape: {data_partition.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary([x_train, y_train, x_val, y_val, x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd71db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image = x_train[0]\n",
    "one_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a92346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(one_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1651f",
   "metadata": {},
   "source": [
    "Can you tell what the class of the image above is!?\n",
    "\n",
    "Let's show more images with their correct class from the CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(x, y, random=False):\n",
    "    \"\"\"\n",
    "    Plots 25 images from x data with titles set as y.\n",
    "    Set random=True if you want random images rather than the first 25.\n",
    "    \"\"\"\n",
    "    \n",
    "    if random:\n",
    "        indices = np.random.choice(range(y.shape[0]), 25, replace=False)\n",
    "    \n",
    "    else:\n",
    "        indices = np.array(range(25))\n",
    "    \n",
    "    fig, axes = plt.subplots(5,5, figsize = (15,15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for ax, index in zip(axes, indices):\n",
    "        ax.imshow(x[index])\n",
    "        ax.set_title(f\"Class: {y[index][0]}\", size=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6ea76",
   "metadata": {},
   "source": [
    "Oh no, the class labels are just digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f040bc6",
   "metadata": {},
   "source": [
    "## Challenge 1: Translate Classes\n",
    "\n",
    "Create a function `translate_class()` that uses the correct class name for the target classes (truck, horse, etc..).\n",
    "- Use the [keras CIFAR10 documentation](https://keras.io/api/datasets/cifar10/) as a guide to know how the classes are labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_class():\n",
    "    # Your code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d29a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODELETE SOLUTION\n",
    "def translate_class(y):\n",
    "    \"\"\"\n",
    "    Takes a class index [0-9] and returns the CIFAR10 class category.\n",
    "    \"\"\"\n",
    "    # Create a list of categories\n",
    "    categories = [\"airplane\", \n",
    "                 \"automobile\",\n",
    "                 \"bird\",\n",
    "                 \"cat\",\n",
    "                 \"deer\",\n",
    "                 \"dog\",\n",
    "                 \"frog\",\n",
    "                 \"horse\",\n",
    "                 \"ship\",\n",
    "                 \"truck\"]\n",
    "    \n",
    "    return categories[y]\n",
    "    \n",
    "    \n",
    "def translate_classes_fancy(y):\n",
    "    \"\"\"\n",
    "    Use a key-value paired dictionary to translate target class\n",
    "    \"\"\"\n",
    "    # Create a list of categories\n",
    "    categories = [\"airplane\", \n",
    "                 \"automobile\",\n",
    "                 \"bird\",\n",
    "                 \"cat\",\n",
    "                 \"deer\",\n",
    "                 \"dog\",\n",
    "                 \"frog\",\n",
    "                 \"horse\",\n",
    "                 \"ship\",\n",
    "                 \"truck\"]\n",
    "    \n",
    "    # Use a dictionary comprehesion to attach class number to category\n",
    "    category_dict = {key : value for key, value in zip(list(range(10)), categories)}\n",
    "    \n",
    "    return category_dict[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b995e",
   "metadata": {},
   "source": [
    "## Challenge 2: Plotting Image Classes\n",
    "\n",
    "Create a new function `my_imageplotter()` that uses code from our `plot_images()` function and incorporates the `translate_class()` to give us the correct class titles in our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0dcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_imageplotter():\n",
    "    # your code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DELETE TEST SOLUTION\n",
    "\n",
    "def my_imageplotter(x, y, random=False):\n",
    "    \"\"\"\n",
    "    Plots 25 images from x data with titles set as y.\n",
    "    Set random=True if you want random images rather than the first 25.\n",
    "    \"\"\"\n",
    "    \n",
    "    if random:\n",
    "        indices = np.random.choice(range(y.shape[0]), 25, replace=False)\n",
    "    \n",
    "    else:\n",
    "        indices = np.array(range(25))\n",
    "    \n",
    "    fig, axes = plt.subplots(5,5, figsize = (15,15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for ax, index in zip(axes, indices):\n",
    "        # New line here\n",
    "        title = translate_class(y[index][0])\n",
    "        ax.imshow(x[index])\n",
    "        ax.set_title(f\"Class: {title}\", size=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5d98c",
   "metadata": {},
   "source": [
    "Test your function below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd13b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imageplotter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b3685",
   "metadata": {},
   "source": [
    "Let's make sure we have balanced class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_distributions(targets, titles):\n",
    "    \"\"\"\n",
    "    Returns the distribution of target classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(3,1, figsize = (10,10))\n",
    "    \n",
    "    for ax, target, title in zip(axes, targets, titles):\n",
    "        ax.hist(target) \n",
    "        ax.set_title(f\"{title} Class Distribution\")\n",
    "    \n",
    "    return plt.show()\n",
    "\n",
    "plot_target_distributions([y_train, y_val, y_test], [\"Train\", \"Validation\", \"Test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bda62d",
   "metadata": {},
   "source": [
    "The last step to prepping our data for modeling is data transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_transform_one_dim(x_data):\n",
    "    \"\"\"\n",
    "    Transforms image data to one dimension.\n",
    "    \"\"\"\n",
    "    \n",
    "    flatten = x_data.reshape((x_data.shape[0], (x_data.shape[1] * x_data.shape[2]*x_data.shape[3])))\n",
    "    scaled = flatten.astype('float32') / 255\n",
    "    \n",
    "    return scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_onedim(x_train, y_train, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Transforms training and validation image data into a single dimension and targets to categorical.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = {}\n",
    "    for x_data, name in zip([x_train, x_val], [\"x_train\", \"x_val\"]):\n",
    "        x_trans = x_transform_one_dim(x_data)\n",
    "        x[name] = x_trans\n",
    "    \n",
    "    y = {}\n",
    "    \n",
    "    for y_data, name in zip([y_train, y_val], [\"y_train\", \"y_val\"]):\n",
    "        y[name] = to_categorical(y_data)\n",
    "    \n",
    "    return x['x_train'], y['y_train'], x['x_val'], y['y_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd920b00",
   "metadata": {},
   "source": [
    "For our first model, let's build a standard (vanilla) feed-forward neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9930d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_ONE_DIM = x_train.shape[1]*x_train.shape[2]*x_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_nn = models.Sequential()\n",
    "vanilla_nn.add(layers.Dense(512, activation= \"relu\", input_shape=(INPUT_SHAPE_ONE_DIM,)))\n",
    "vanilla_nn.add(layers.Dropout(0.5))\n",
    "vanilla_nn.add(layers.Dense(512, activation= \"relu\"))\n",
    "vanilla_nn.add(layers.Dropout(0.5))\n",
    "vanilla_nn.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "vanilla_nn.compile(optimizer= \"rmsprop\",\n",
    "                  loss = \"categorical_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409d79b",
   "metadata": {},
   "source": [
    "In order to save memory with data transformation, instead of creating new objects in our global environment of our transformed data, we will create a function that uses the transformation function within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train_model(transformation_func, model, x_train, y_train, x_val, y_val, epochs = 20, batch_size = 128):\n",
    "    \"\"\"\n",
    "    Takes a transformation function, a compiled model, data, and optional fitting arguments.\n",
    "    \n",
    "    Trains the model and returns the history.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transforms the data\n",
    "    x_train_trans, y_train_trans, x_val_trans, y_val_trans = transformation_func(x_train, y_train, x_val, y_val)\n",
    "    \n",
    "    # Trains the model\n",
    "    history = model.fit(x_train_trans, \n",
    "                              y_train_trans, \n",
    "                              epochs=epochs,\n",
    "                              batch_size=batch_size,\n",
    "                              validation_data=(x_val_trans, y_val_trans))\n",
    " \n",
    "    return history\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbced83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_history = transform_train_model(transform_data_onedim,\n",
    "                                        vanilla_nn,\n",
    "                                        x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f84f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_accuracy(history_dict):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy of a neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, color = 'navy', alpha = 0.8, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, color = 'green', label='Validation Accuracy')\n",
    "    plt.title('Training and validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrong_predictions(transformation_func, model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Plots 25 incorrectly predicted images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform data\n",
    "    x_test_trans = transformation_func(x_test)[:26]\n",
    "    y_test_trans = to_categorical(y_test)[:26]\n",
    "    \n",
    "    # Format predictions and targets\n",
    "    predictions = model.predict(x_test_trans)\n",
    "    predicted = np.argmax(predictions, axis = 1)\n",
    "    target = np.argmax(y_test_trans, axis = 1)\n",
    "    \n",
    "    # Set up subplots\n",
    "    fig, axes = plt.subplots(5,5, figsize = (25,25))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for ax, index in zip(axes, range(25)):\n",
    "        ax.imshow(x_test[index], cmap=plt.cm.binary, interpolation='nearest')\n",
    "        prediction_title = translate_class(predicted[index])\n",
    "        target_title = translate_class(target[index])\n",
    "        \n",
    "        # Color title based on if prediction is correct\n",
    "        if predicted[index] == target[index]:\n",
    "            color = \"green\"\n",
    "        else:\n",
    "            color = \"red\"\n",
    "            \n",
    "        ax.set_title(f\"Predicted {prediction_title}, Actual is {target_title}\", color = color)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e765a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(vanilla_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wrong_predictions(x_transform_one_dim, vanilla_nn, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85813ccb",
   "metadata": {},
   "source": [
    "Interesting..... \n",
    "\n",
    "While this model architecture that gave us great results to predict the MNIST handwritten digits, it performs poorly on the CIFAR image classification task..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd1280",
   "metadata": {},
   "source": [
    "#### Challenge 3\n",
    "1. Why do you think the vanilla neural network performs worse on CIFAR than it did on the MNIST image classification?\n",
    "2. Why might we prefer a convolutional neural network to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e906899",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff963d3",
   "metadata": {},
   "source": [
    "Let's jump right in and build a convolutional neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a73818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_transform_three_dim(x_data):\n",
    "    \"\"\"\n",
    "    Transforms image data into three dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaled = x_data.astype('float32') / 255\n",
    "    \n",
    "    return scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddbca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_threedim(x_train, y_train, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Transforms training and validation image data into a single dimension and targets to categorical.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = {}\n",
    "    for x_data, name in zip([x_train, x_val], [\"x_train\", \"x_val\"]):\n",
    "        x_trans = x_transform_three_dim(x_data)\n",
    "        x[name] = x_trans\n",
    "    \n",
    "    y = {}\n",
    "    \n",
    "    for y_data, name in zip([y_train, y_val], [\"y_train\", \"y_val\"]):\n",
    "        y[name] = to_categorical(y_data)\n",
    "    \n",
    "    return x['x_train'], y['y_train'], x['x_val'], y['y_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598bdd5",
   "metadata": {},
   "source": [
    "Before writing code to build a convolutional neural network, let's quickly review what the significance a convolutional neural network is, the convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ac9d6",
   "metadata": {},
   "source": [
    "#### Convolutional layers\n",
    "As reviewed in our slides, convolutional layers contain *filters* that we *stride* along our image to find matching patterns, producing a *response map*. \n",
    "\n",
    "![title](https://qph.fs.quoracdn.net/main-qimg-6428cf505ac1e9e1cf462e1ec8fe9a68)\n",
    "- The green boxes represent the pixels in our input image.\n",
    "- The yellow boxes represent the *filter*.\n",
    "- The movement of the filter represents the *stride*.\n",
    "- The red boxes represent our *response map*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4f866",
   "metadata": {},
   "source": [
    "We initialize a convolutional neural network the same way we did a vanilla neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1a5aa",
   "metadata": {},
   "source": [
    "We now add our first convolutional layer. \n",
    "\n",
    "*Note: I use the argument names here to clarify what parameters we are passing into our neural network including default values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.add(layers.Conv2D(filters = 32,\n",
    "                          kernel_size = (3, 3),\n",
    "                          strides = (1,1),\n",
    "                          activation= \"relu\",\n",
    "                          input_shape=(32, 32, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27738946",
   "metadata": {},
   "source": [
    "We define our first Convolution layer using:\n",
    "`.add(layers.Conv2D(...))`\n",
    "- This adds a convolutional layer to our model object.\n",
    "\n",
    "`filters = 32`\n",
    "- Initializes 32 filters total.\n",
    "- Each filter slides along the entire image.\n",
    "- Each filter produce a response map.\n",
    "\n",
    "`kernel_size = (3, 3)`\n",
    "- Specifies the \"kernel\" size of the filters.\n",
    "- (3 x 3) : (height x width)\n",
    "    \n",
    "`strides = (1,1)`\n",
    "- The filter strides by one unit in both the horizontal and vertical dimension.\n",
    "- (1 x 1) or (height stride x width stride)\n",
    "\n",
    "`activation= \"relu\"`\n",
    "- Uses the relu (Rectified Linear Unit) activation function on the output from striding our filter over the input.\n",
    "- This simply causes any negative values to be 0, and other values to stay the same.\n",
    "\n",
    "`input_shape=(32, 32, 3)`\n",
    "- Specifies the shape of our input data\n",
    "- 32 pixels wide\n",
    "- 32 pixels high\n",
    "- 3 channels deep (Red, Green, Blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5d071",
   "metadata": {},
   "source": [
    "#### Max Pooling layers\n",
    "After a convolutional layer, we can downsample a *reponse map* using a maxpooling layer. This simply takes the maximum value for a given kernel-size sliding along our response map, much like a filter. \n",
    "\n",
    "Maxpooling has a dual benefit. Not only does it effectively reduce the amount of data we must process, but it also improves our focus on finding **good** matches from our filter, making our model less specific about the location where it was found (location invariance).\n",
    "\n",
    "![title](https://nico-curti.github.io/NumPyNet/NumPyNet/images/maxpool.gif)\n",
    "- The blue boxes represent our *response map*.\n",
    "- The purple box represent our kernel size (2 x 2).\n",
    "- The yellow box is the output of our maxpooling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.add(layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                               strides = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee720ea",
   "metadata": {},
   "source": [
    "`.add(layers.MaxPooling2D(...))`\n",
    "- Adds a maxpooling layer.\n",
    "\n",
    "`pool_size=(2, 2)`\n",
    "- Defines the \"kernel\" size of our maxpooling operation.\n",
    "- Will return a single value from this entire window\n",
    "\n",
    "`strides = None`\n",
    "- None makes it so there is no overlap during striding, just continue to inputs not in the previous window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c39fe0",
   "metadata": {},
   "source": [
    "We add two more convolutional layers, separated by a maxpooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.add(layers.Conv2D(64, (3, 3), activation= \"relu\"))\n",
    "convnet.add(layers.MaxPooling2D((2, 2)))\n",
    "convnet.add(layers.Conv2D(64, (3, 3), activation= \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9494618",
   "metadata": {},
   "source": [
    "#### Dense layers\n",
    "Until this point, the convolutional and maxpooling layers have been performing feature extraction.\n",
    "\n",
    "In order to classify our images we return to our good old dense layer, the same we used in our vanilla neural networks. \n",
    "\n",
    "Before we can use our dense layer, we first flatten the data passed through the convolutional and maxpooling layers (which are high dimensional) into a single dimension.\n",
    "\n",
    "We then use a dense layer that is able to *look* at the all of the features extracted from the convolutional operations, and optimize its weights to correctly associate these features with the correct class.\n",
    "\n",
    "Finally we have our output layer, which contains the same number of neurons as classes we are predicting. We use a softmax activation function, giving us the probability for each class in our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.add(layers.Flatten())\n",
    "convnet.add(layers.Dense(64, activation= \"relu\"))\n",
    "convnet.add(layers.Dense(10, activation= \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c022acf",
   "metadata": {},
   "source": [
    "#### Compiling\n",
    "We now compile our model as we have done previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c746cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.compile(optimizer= \"rmsprop\",\n",
    "               loss= \"categorical_crossentropy\", \n",
    "               metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eade4",
   "metadata": {},
   "source": [
    "Below we train our model, a quick warning that this will take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet_history = transform_train_model(transform_data_threedim,\n",
    "                                        convnet,\n",
    "                                        x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f672e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(convnet_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99565252",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_wrong_predictions(x_transform_three_dim, \n",
    "                      convnet,\n",
    "                      x_test,\n",
    "                      y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97702e09",
   "metadata": {},
   "source": [
    "## Challenge 4: Build your own neural network\n",
    "\n",
    "1. Build your own convolution neural network with a custom architecture.\n",
    "2. Plot the training and validation accuracy on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc610368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfecb6d1",
   "metadata": {},
   "source": [
    "The neural networks we built are relatively small compared to those used in applications such as google photos or inaturalist.\n",
    "\n",
    "Let's compare the architecture from the models we built with a popular convolutional neural network called [VGG16](https://arxiv.org/pdf/1409.1556.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0dd8b8",
   "metadata": {},
   "source": [
    "### Vanilla Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ce78f",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe73384",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe75db2",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbe639",
   "metadata": {},
   "source": [
    "![title](https://alexisbcook.github.io/assets/vgg16_keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d391081",
   "metadata": {},
   "source": [
    "## Hardware for Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37b8fb",
   "metadata": {},
   "source": [
    "We are highly restricted in our ability to train larger models due to our hardware. While there are many aspects about hardware that are critical to deep learning, we will focus on one major concept, the Processing Unit.\n",
    "\n",
    "All computers have a Central Processing Unit (CPU) that performs all of the operations your computer needs to do, including running all this python code!\n",
    "\n",
    "For deep-learning, CPUs are not very efficient at running the massive number operations required to train deep neural networks. That's where the Graphical Proccessing Unit (GPU) comes into the picture. \n",
    "\n",
    "GPUs, originally designed to process many operations to render complex graphics have been repurposed for training neural networks! This key innovation behind this change came in 2007 when NVIDIA launched [CUDA](https://developer.nvidia.com/about-cuda), a programming interface for GPUs which allows highly parallelizable computations. Since many neural networks operations are parallelizable, this has become the go-to way to train large neural network models.\n",
    "\n",
    "*Loosely based on: (Chollet 2018) Deep Learning with Python*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4e3cf",
   "metadata": {},
   "source": [
    "The code below allows you to see the available hardware (CPUs, GPUs) that can be used in tensorflow/keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba109c6",
   "metadata": {},
   "source": [
    "### Final words\n",
    "\n",
    "So are we doomed? Can only the tech giants create deep neural networks?\n",
    "\n",
    "Well.. sorta, but we do have alternatives, we just need to be creative! Here are some options to train your own deep neural networks that may aren't possible on your own machine:\n",
    "1. Use other services\n",
    "\n",
    "    - Google Colab offers free could instances of a Jupyter Notebook-like environment with GPUs onboard even in their free tier!\n",
    "    - Amazon Web Services (AWS) allows you to use their hardware in \"EC2 instances\" to train your models offerring a [dizzying number of options](https://aws.amazon.com/ec2/instance-types/). Note that this can be expensive and is billed by time!\n",
    "    \n",
    "2. Transfer learning\n",
    "    - Why build your model from the ground up?\n",
    "    - Transfer learning uses an existing model with all it's tuned weights, and retrains just the final portion of the model to a new task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed978565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
