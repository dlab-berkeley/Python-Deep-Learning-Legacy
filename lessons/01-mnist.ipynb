{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd23324",
   "metadata": {},
   "source": [
    "# Neural Networks in Keras with MNIST\n",
    "\n",
    "**Time**\n",
    "- Teaching: 2.5 hours\n",
    "- Challenges: 30 minutes\n",
    "\n",
    "**Questions**\n",
    "- \"How to we load and manipulate input data for deep learning?\"\n",
    "- \"How can we use keras to design custom neural networks?\"\n",
    "- \"How do we validate our models?\"\n",
    "- \"How do we decide neural network architectures that perform best on MNIST?\"\n",
    "- \"How do we compare our models and test their ability to generalize?\"\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "- \"Understand the data format of inputs to neural networks.\"\n",
    "- \"The ability to implement, troubleshoot, and modify your own neural networks.\"\n",
    "\n",
    "* * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d232252d",
   "metadata": {},
   "source": [
    "## Install packages\n",
    "\n",
    "If your browser url adress is currently: \n",
    "\n",
    "`https://dlab.datahub.berkeley.edu/user/YOURNAME`\n",
    "\n",
    "Then you are good to go! You are in the dlab's datahub which already has the packages needed to get started along with 2GB of memory.\n",
    "\n",
    "If you want to work locally you need to:\n",
    "1. Make sure you have a working version of Python\n",
    "2. Install Keras\n",
    "3. Install Jupyter\n",
    "\n",
    "TODO: Add specific windows/mac instructions and test on system.\n",
    "- My preference is to do this in a venv/conda, but that may create too much technical overhead :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d0fda",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "After installation is complete, we now are able to import the keras library. In order to simplify the syntax we will import the specific functions we need from keras.\n",
    "\n",
    "Note you can simply import keras, then call each function from the module, for example:\n",
    "\n",
    "`from tensorflow import keras`\n",
    "\n",
    "`keras.dataset.mnist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f813f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Note you may get a warning about CUDA and GPU set up\n",
    "# You can ignore these for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1b58c",
   "metadata": {},
   "source": [
    "We also need to import packages to help us with visualizing and manipulating out data. Remember, this is half the battle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d96314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253cf87a",
   "metadata": {},
   "source": [
    "### Keras and MNIST\n",
    "\n",
    "Keras, Tensorflow, and MNIST, oh my! \n",
    "\n",
    "#### Keras\n",
    "A deep-learning framework developed by google with a user-friendly API built for researchers to quickly prototype models.\n",
    "\n",
    "#### Tensorflow\n",
    "A backend engine for Keras.\n",
    "\n",
    "#### MNIST\n",
    "A dataset of 60,000 training images and 10,000 test images of handwritten digits. It is often considered the \"hello world\" of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263315d",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "\n",
    "You work for a bank and they need to automate the processing of reading mobile check deposits. \n",
    "\n",
    "At they moment they have overworked staff, looking at each photo of the checks and manually inputting the check number, account number, and amount of money. \n",
    "\n",
    "Can we make their life easier!?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacec302",
   "metadata": {},
   "source": [
    "<img src=\"https://www.usglobalmail.com/wp-content/uploads/2016/12/check-deposits.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e62029",
   "metadata": {},
   "source": [
    "#### Our Solution\n",
    "\n",
    "We will build a model that can correctly identify numbers from a picture.\n",
    "\n",
    "As a first pass, we want to build a model that can take as input an image of a single handwritten digit, and predict the correct target digit.\n",
    "\n",
    "Let's dive right in and build a neural network model with keras that is able identify handwritten digits! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676450f",
   "metadata": {},
   "source": [
    "## Input Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bfe53",
   "metadata": {},
   "source": [
    "They say 80% of a Data Scientists work is data cleaning.\n",
    "\n",
    "Getting data in the right format is a non-trivial and critical task when  building deep learning models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c42b7",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(subset=True):\n",
    "    \"\"\"\n",
    "    Returns the MNIST dataset as a tuple:\n",
    "    (x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    \n",
    "    When subset=TRUE:\n",
    "    Returns only a subset of the mnist dataset.\n",
    "    Especially important to use if you are on datahub and only have 1-2GB of memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    if subset:\n",
    "        N_TRAIN = 5000\n",
    "        N_VALIDATION = 1000\n",
    "        N_TEST = 1000\n",
    "    else:\n",
    "        N_TRAIN = 48000\n",
    "        N_VALIDATION = 12000\n",
    "        N_TEST = 10000\n",
    "    \n",
    "    (x_train_and_val, y_train_and_val), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train_and_val[:N_TRAIN,:,:]\n",
    "    y_train = y_train_and_val[:N_TRAIN]\n",
    "    \n",
    "    x_val = x_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION,:,:]\n",
    "    y_val = y_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION]\n",
    "    \n",
    "    x_test = x_test[:N_TEST]\n",
    "    y_test = y_test[:N_TEST]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be26764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Set subset=False if you want to use the full dataset!\n",
    "# Note that this will require 2+ GB of memory and will make training take longer\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_mnist_data(subset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c8cda",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aeca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(data):\n",
    "    \"\"\"\n",
    "    Takes a list of our data partitions and returns the shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, data_partition in enumerate(data):\n",
    "        if i == 0:\n",
    "            print(\"Training Data\")\n",
    "        elif i == 2:\n",
    "            print()\n",
    "            print(\"Validation Data\")\n",
    "        elif i == 4:\n",
    "            print()\n",
    "            print(\"Testing Data\")\n",
    "\n",
    "        print(f\"Shape: {data_partition.shape}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary([x_train, y_train, x_val, y_val, x_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428fa7a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the Input Data\n",
    "\n",
    "1. Why do we split our data into train, validation, and test sets?\n",
    "2. What is the shape of our input data partitions?\n",
    "3. What is the type of the data?\n",
    "\n",
    "**BONUS:**\n",
    "\n",
    "4. What is the distribution of the target classes within the data, is it balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbbfef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7aa18bb",
   "metadata": {},
   "source": [
    "### Understanding and visualizing the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c364eb7",
   "metadata": {},
   "source": [
    "Let's extract just one example from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image = x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b014c0",
   "metadata": {},
   "source": [
    "Let's look inside and see how it's stored!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bcabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74e383",
   "metadata": {},
   "source": [
    "Not very helpful to see the data in it's raw format \n",
    "\n",
    "Instead, let's utilize the shape attribute and matplotlib to help us visualize this image data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206f70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(one_image, cmap=plt.cm.binary);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b9c5a",
   "metadata": {},
   "source": [
    "Which dimension represent rows vs. columns in our image?\n",
    "\n",
    "Let's find out through a test by grabbing all of the first dimension, and half of the second.\n",
    "\n",
    "If the image is cutoff column-wise, we know the dimensions are \\[ row pixel, column pixel \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image_first_dimension = one_image[:,0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(one_image_first_dimension, cmap=plt.cm.binary);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6cff4",
   "metadata": {},
   "source": [
    "So now we feel solid with our input data format!\n",
    "\n",
    "The input data has 3 dimensions \\[ index for image, pixel row, pixel column \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89753677",
   "metadata": {},
   "source": [
    "### Building a Neural Network in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b2bd9",
   "metadata": {},
   "source": [
    "First we define our neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_network = Sequential()\n",
    "first_network.add(Dense(64, activation= \"relu\", input_shape=(28*28,)))\n",
    "first_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a2acc3",
   "metadata": {},
   "source": [
    "We define a simple neural network with a single \"hidden\" layer, not very *deep*.\n",
    "\n",
    "We can check out a summary of our model layout with the method `model_object.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a18a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f95153",
   "metadata": {},
   "source": [
    "Even this TINY neural network has over 50,000 parameters!\n",
    "\n",
    "Next we need to give the model:\n",
    "1. An optimizer strategy\n",
    "2. A way to calculate loss\n",
    "3. The metric we want to get out during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712fdc57",
   "metadata": {},
   "source": [
    "Lastly, we train the model using the `model_name.fit()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f703738",
   "metadata": {},
   "source": [
    "If you run the code below.... you would find that the model would fail to train. I do not suggest running it to save memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = first_network.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9fda6",
   "metadata": {},
   "source": [
    "Remember that half the battle with model training is understanding what format we need the data in!\n",
    "\n",
    "We won't go over this in too much detail, but in a snapshot we will:\n",
    "1. Flatten the pixel dimensions from (28,28) into a single dimension (784)\n",
    "2. Change x data type from integer with pixel values \\[0, 225\\] to a float values \\[0,1\\].\n",
    "3. Expand the y targets from a single dimension with values \\[0:9\\] to 10 dimensions each representing a target class. \n",
    "    - In each row, the target class column will have a value of 1, while the other columns will have a value of 0\n",
    "    - This is a common technique to reformat categorical targets known as [One Hot Encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(xdata, ydata):\n",
    "    \"\"\"\n",
    "    Deletes the current data partitions.\n",
    "    Reads in MNIST data.\n",
    "    Transforms image data:\n",
    "        1. Flattens pixel dimensions from 2 -> 1\n",
    "        2. Scales pixel values between [0,1]\n",
    "    \"\"\"\n",
    "    \n",
    "    x = {}\n",
    "    for name, partition in zip([\"x_train\", \"x_val\", \"x_test\"],xdata):\n",
    "        flatten = partition.reshape((partition.shape[0], 28 * 28))\n",
    "        scaled = flatten.astype('float32') / 255\n",
    "        x[name] = scaled\n",
    "    \n",
    "    y = {}\n",
    "    for name, partition in zip([\"y_train\", \"y_val\", \"y_test\"],ydata):\n",
    "        y[name] = to_categorical(partition)\n",
    "    \n",
    "    return x['x_train'], y['y_train'], x['x_val'], y['y_val'], x['x_test'], y['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trans, y_train_trans, x_val_trans, y_val_trans, x_test_trans, y_test_trans = transform_data([x_train, x_val, x_test],\n",
    "                                                                                                    [y_train, y_val, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary([x_train_trans, y_train_trans, x_val_trans, y_val_trans, x_test_trans, y_test_trans])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e48488",
   "metadata": {},
   "source": [
    "We have succesfully flattened our input images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f845ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = first_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=5, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221b829",
   "metadata": {},
   "source": [
    "### Visualizing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_accuracy(history_dict):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy of a neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, color = 'navy', alpha = 0.8, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, color = 'green', label='Validation Accuracy')\n",
    "    plt.title('Training and validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ea650",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7b7e7",
   "metadata": {},
   "source": [
    "Not too shabby for a *tiny* neural network!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_network = Sequential()\n",
    "second_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "second_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b65e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_two = second_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=5, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_two.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e90cc7",
   "metadata": {},
   "source": [
    "How are you doing now?\n",
    "\n",
    "Let's keep training this model for a few more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a718300",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_two_more_epochs = second_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=10, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_epoch_plot(history_dicts):\n",
    "    \"\"\"\n",
    "    Combines two history dictionaries for extended epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_history = {key: [] for key in history_dicts[0].keys()}\n",
    "    \n",
    "    for hist in history_dicts:\n",
    "        for key in combined_history.keys():\n",
    "            combined_history[key].extend(hist[key])\n",
    "    \n",
    "    return plot_epoch_accuracy(combined_history)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695900f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_epoch_plot([history_two.history, history_two_more_epochs.history])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256e3d8",
   "metadata": {},
   "source": [
    "Diagnosing our accuracy plot, it looks like even with more epochs, our model is *still* failing to generalize. \n",
    "\n",
    "The dunning kruger effect in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc940a68",
   "metadata": {},
   "source": [
    "One solution is to give our network more nodes/neurons in our hidden layer to extract more features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_network = Sequential()\n",
    "third_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "third_network.add(Dense(512, activation= \"relu\"))\n",
    "third_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e262e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_two_layers = third_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=10, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_two_layers.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae52cb",
   "metadata": {},
   "source": [
    "Our model is still failing to generalize and reach validation accuracy that approaches the training accuracy!\n",
    "\n",
    "One way we can prevent our model from overfitting to the training data is to add dropout in our hidden layers.\n",
    "\n",
    "### TLDR for Dropout\n",
    "Dropout makes our network a bit \"forgetful\" during training. We get to set a proportion of neurons the network will randomly \"forget\" or \"drop\", which we set as a probability in the `model.add(Dropout(probability_here))` function.\n",
    "\n",
    "This forces our model to generalize, preventing it from overfitting to the training data. \n",
    "\n",
    "Check out [Hinton et al. 2012](https://arxiv.org/abs/1207.0580) describing how dropout helps neural network generalization.\n",
    "- *Fun fact: they also use MNIST to test model generalization :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff735c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_network = Sequential()\n",
    "fourth_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "fourth_network.add(Dropout(0.5))\n",
    "fourth_network.add(Dense(512, activation= \"relu\"))\n",
    "fourth_network.add(Dropout(0.5))\n",
    "fourth_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f366fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = fourth_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=20, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63f132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_dropout.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1cbca",
   "metadata": {},
   "source": [
    "After implementing dropout, do you think the model is better able to generalize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a24c3b",
   "metadata": {},
   "source": [
    "## Challenge 2: Build your own neural network\n",
    "\n",
    "1. Try training a new neural network that has a different:\n",
    "    - Architecture\n",
    "    - Activation Function\n",
    "    - Epochs\n",
    "2. How does the validation accuracy compare to the one we made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e16f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9a307c",
   "metadata": {},
   "source": [
    "Now that we are satisfied with this model, let's see how it performs on our holdout test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53264eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes a model and a test set of data.\n",
    "    Returns the accuracy.\n",
    "    \"\"\"\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    accuracy = round(score[1]*100, 1)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_accuracy(fourth_network, x_test_trans, y_test_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c43ff",
   "metadata": {},
   "source": [
    "How does this compare with our other models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mod in enumerate([first_network, second_network, third_network, fourth_network]):\n",
    "    acc = get_model_accuracy(mod, x_test_trans, y_test_trans)\n",
    "    print(f\"Model {i+1} has an accuracy of {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed1dea",
   "metadata": {},
   "source": [
    "## Challenge 3: Evaluate your own model\n",
    "\n",
    "Use your own model from challenge 2 to evaluate its performance on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916e30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd1b345",
   "metadata": {},
   "source": [
    "### Visualize the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrong_predictions(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Plots 25 incorrectly predicted images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Back transform images\n",
    "    x_images = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "    \n",
    "    # Format predictions and targets\n",
    "    predictions = model.predict(x_test)\n",
    "    predicted = np.argmax(predictions, axis=1)\n",
    "    target = np.argmax(y_test, axis = 1)\n",
    "    \n",
    "    # Get wrong indices\n",
    "    wrong_indices = np.where(predicted != target)[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(5,5, figsize = (25,25))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for ax, index in zip(axes, wrong_indices[:26]):\n",
    "        ax.imshow(x_images[index], cmap=plt.cm.binary, interpolation='nearest')\n",
    "        ax.set_title(f\"Predicted {predicted[index]}, Actual is {target[index]}\")\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6513237",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wrong_predictions(fourth_network, x_test_trans, y_test_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819253a",
   "metadata": {},
   "source": [
    "Do you feel our model made reasonable mistakes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e080295",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556d32e",
   "metadata": {},
   "source": [
    "The neural networks we have created so far are known as *vanilla neural networks*. \n",
    "\n",
    "These have many great usecases, but for problems in computer vision, we often use a different architecture called covolutional neural networks.\n",
    "\n",
    "We will review the the details of how the work in our slides tomorrow, but for today, let's just compare their efficacy to vanilla neural nets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "convnet.add(MaxPooling2D((2, 2)))\n",
    "convnet.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "convnet.add(MaxPooling2D((2, 2)))\n",
    "convnet.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(64, activation='relu'))\n",
    "convnet.add(Dense(10, activation='softmax'))\n",
    "\n",
    "convnet.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3832f0",
   "metadata": {},
   "source": [
    "Since our convnet has a *sense* of the two-dimensional image, we need to back transform our images to be two dimensional.\n",
    "\n",
    "Why not use the original pixel data then?\n",
    "\n",
    "We still want to keep the transformation of values between \\[0, 1\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_transform_2d(data):\n",
    "    \"\"\"\n",
    "    Takes a list of flattened input pixel data.\n",
    "    Reshapes pixel data from a single vector to two dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    two_dimensional_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        transformed = d.reshape(d.shape[0], 28, 28, 1)\n",
    "        two_dimensional_data.append(transformed)\n",
    "    \n",
    "    return [t for t in two_dimensional_data]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2d, x_val_2d, x_test_2d = back_transform_2d([x_train_trans, x_val_trans, x_test_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_convnet = convnet.fit(x_train_2d,\n",
    "                              y_train_trans, \n",
    "                              epochs=10, \n",
    "                              batch_size=128, \n",
    "                              validation_data=(x_val_2d, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ed138",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_convnet.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002e6e7",
   "metadata": {},
   "source": [
    "So how well does our CNN perform on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cffbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_accuracy(convnet,x_test_2d, y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fba9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wrong_predictions(convnet, x_test_2d, y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad991c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
