{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd23324",
   "metadata": {},
   "source": [
    "# Neural Networks in Keras with MNIST\n",
    "\n",
    "**Time**\n",
    "- Teaching: 2 hours\n",
    "- Challenges: 30 minutes\n",
    "\n",
    "**Questions**\n",
    "- \"How to we load and manipulate input data for deep learning?\"\n",
    "- \"How can we use keras to design custom neural networks?\"\n",
    "- \"How do we validate our models?\"\n",
    "- \"How do we decide neural network architectures that perform best on MNIST?\"\n",
    "- \"How do we compare our models and test their ability to generalize?\"\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "- \"Understand and wrangle input to neural networks.\"\n",
    "- \"The ability to implement, troubleshoot, and modify your own neural networks.\"\n",
    "\n",
    "* * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d232252d",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If your browser url adress is currently: \n",
    "\n",
    "`https://dlab.datahub.berkeley.edu/user/YOURNAME`\n",
    "\n",
    "Then you are good to go! You are in the dlab's datahub which already has the packages you need to get started along with 2GB of memory.\n",
    "\n",
    "If you want to work locally on your computer, you should have already followed the installation instructions at <https://github.com/dlab-berkeley/Python-Deep-Learning/blob/main/installation-instructions.md> \n",
    "\n",
    "If you haven't yet installed keras and tensorflow locally, I highly suggest using the dlab.datahub for this workshop (link in the installation instructions above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d0fda",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "After installation is complete, we now are able to import the keras library. In order to simplify the syntax we will import the specific functions we need from keras.\n",
    "\n",
    "Note you can simply import keras, then call each function from the module, for example:\n",
    "\n",
    "`from tensorflow import keras`\n",
    "\n",
    "`keras.dataset.mnist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f813f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Note you may get a warning about CUDA and GPU set up\n",
    "# You can ignore these for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1b58c",
   "metadata": {},
   "source": [
    "We also need to import packages to help us with visualizing and manipulating out data. Remember, this is half the battle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d96314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253cf87a",
   "metadata": {},
   "source": [
    "### Keras and MNIST\n",
    "\n",
    "Keras, Tensorflow, and MNIST, oh my! \n",
    "\n",
    "#### Keras\n",
    "A deep-learning framework developed by google with a user-friendly API built for researchers to quickly prototype models.\n",
    "\n",
    "#### Tensorflow\n",
    "A backend engine for Keras.\n",
    "\n",
    "#### MNIST\n",
    "A dataset of 60,000 training images and 10,000 test images of handwritten digits. It is often considered the \"hello world\" of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263315d",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "\n",
    "You work for a bank and they need to automate the processing of reading mobile check deposits. \n",
    "\n",
    "At they moment they have overworked staff, looking at each photo of the checks and manually inputting the check number, account number, and amount of money. \n",
    "\n",
    "Can we make their life easier!?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacec302",
   "metadata": {},
   "source": [
    "<img src=\"https://www.usglobalmail.com/wp-content/uploads/2016/12/check-deposits.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e62029",
   "metadata": {},
   "source": [
    "#### Our Solution\n",
    "\n",
    "We will build a model that can correctly identify numbers from a picture.\n",
    "\n",
    "As a first pass, we want to build a model that can take as input an image of a single handwritten digit, and predict the correct target digit.\n",
    "\n",
    "Let's dive right in and build a neural network model with keras that is able identify handwritten digits! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676450f",
   "metadata": {},
   "source": [
    "## Input Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bfe53",
   "metadata": {},
   "source": [
    "They say 80% of data analysis is data cleaning.\n",
    "\n",
    "Getting data in the right format is a non-trivial and critical task when  building deep learning models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c42b7",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(subset=True):\n",
    "    \"\"\"\n",
    "    Returns the MNIST dataset as a tuple:\n",
    "    (x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    \n",
    "    When subset=TRUE:\n",
    "    Returns only a subset of the mnist dataset.\n",
    "    Especially important to use if you are on datahub and only have 1-2GB of memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    if subset:\n",
    "        N_TRAIN = 5000\n",
    "        N_VALIDATION = 1000\n",
    "        N_TEST = 1000\n",
    "    else:\n",
    "        N_TRAIN = 48000\n",
    "        N_VALIDATION = 12000\n",
    "        N_TEST = 10000\n",
    "    \n",
    "    (x_train_and_val, y_train_and_val), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train_and_val[:N_TRAIN,:,:]\n",
    "    y_train = y_train_and_val[:N_TRAIN]\n",
    "    \n",
    "    x_val = x_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION,:,:]\n",
    "    y_val = y_train_and_val[N_TRAIN: N_TRAIN + N_VALIDATION]\n",
    "    \n",
    "    x_test = x_test[:N_TEST]\n",
    "    y_test = y_test[:N_TEST]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be26764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Set subset=False if you want to use the full dataset!\n",
    "# Note that this will require 2+ GB of memory and will make training take longer\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_mnist_data(subset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c8cda",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aeca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(data):\n",
    "    \"\"\"\n",
    "    Takes a list of our data partitions and returns the shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, data_partition in enumerate(data):\n",
    "        if i == 0:\n",
    "            print(\"Training Data\")\n",
    "        elif i == 2:\n",
    "            print()\n",
    "            print(\"Validation Data\")\n",
    "        elif i == 4:\n",
    "            print()\n",
    "            print(\"Testing Data\")\n",
    "\n",
    "        print(f\"Shape: {data_partition.shape}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary([x_train, y_train, x_val, y_val, x_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428fa7a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the Input Data\n",
    "\n",
    "1. Why do we split our data into train, validation, and test sets?\n",
    "2. What is the shape of our input data partitions?\n",
    "3. What is the type of the data?\n",
    "\n",
    "**BONUS:**\n",
    "\n",
    "4. What is the distribution of the target classes within the data, is it balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbbfef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7aa18bb",
   "metadata": {},
   "source": [
    "### Understanding and visualizing the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c364eb7",
   "metadata": {},
   "source": [
    "Let's extract just one example from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image = x_train[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b014c0",
   "metadata": {},
   "source": [
    "Let's look inside and see how it's stored!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bcabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74e383",
   "metadata": {},
   "source": [
    "Not very helpful to see the data in it's raw format \n",
    "\n",
    "Instead, let's utilize the shape attribute and matplotlib to help us visualize this image data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206f70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(one_image, cmap=plt.cm.binary);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b9c5a",
   "metadata": {},
   "source": [
    "Which dimension represent rows vs. columns in our image?\n",
    "\n",
    "Let's find out through a test by grabbing all of the first dimension, and half of the second.\n",
    "\n",
    "If the image is cutoff column-wise, we know the dimensions are \\[ row pixel, column pixel \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image_first_dimension = one_image[:,0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(one_image_first_dimension, cmap=plt.cm.binary);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6cff4",
   "metadata": {},
   "source": [
    "So now we feel solid with our input data format!\n",
    "\n",
    "The input data has 3 dimensions \\[ index for image, pixel row, pixel column \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89753677",
   "metadata": {},
   "source": [
    "### Building a Neural Network in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b2bd9",
   "metadata": {},
   "source": [
    "First we define our neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_network = Sequential()\n",
    "\n",
    "first_network.add(Dense(units = 64,\n",
    "                        activation= \"relu\",\n",
    "                        input_shape=(28*28,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a2acc3",
   "metadata": {},
   "source": [
    "Let's review the python code we used to initialize this neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943a74f",
   "metadata": {},
   "source": [
    "#### Hidden Layer\n",
    "\n",
    "`first_network = Sequential()`\n",
    "* This line initializes our model object.\n",
    "\n",
    "`first_network.add(Dense(...))`\n",
    "* The add method adds a layer to our model object, specifically a dense layer.\n",
    "\n",
    "`units = 64`\n",
    "* Within our dense layer, we specify the number of units or *neurons* we want in our layer.\n",
    "\n",
    "`activation= \"relu\"`\n",
    "* We also specify the activation function we want to use, in this case we use the Rectified Linear Unit (relu).\n",
    "* This simple activation unit returns x if x > 0, or 0 if x <= 0. \n",
    "* A critical component to add non-linearity to our network.\n",
    "\n",
    "`input_shape=(28*28,)`\n",
    "* In our first layer must always define the input shape. \n",
    "* We pass a single dimensional vector of size 28 \\* 28 = 784\n",
    "* This represents the number of pixels in a single dimension.\n",
    "* We add the comma to pass in our input shape a tuple.\n",
    "* Note that subsequent layers we add will already know their input sizes since they are inferred from the previous layer's output size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_network.add(Dense(units = 10,\n",
    "                        activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1a9ba",
   "metadata": {},
   "source": [
    "#### Output Layer\n",
    "`first_network.add(Dense(...))`\n",
    "* We add our output layer using the same syntax as our hidden layer.\n",
    "\n",
    "`units = 10`\n",
    "* We give this layer 10 units or *neurons* corresponding to the number of classes we are attempting to classify.\n",
    "\n",
    "`activation = \"softmax\"`\n",
    "* We use the softmax activation function for our output layer which gives us back a probability for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bd067",
   "metadata": {},
   "source": [
    "We just built our first neural network! It's a simple neural network with a single \"hidden\" layer, not very *deep*.\n",
    "\n",
    "We can check out a summary of our model layout with the method `model_object.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a18a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f95153",
   "metadata": {},
   "source": [
    "Even this TINY neural network has over 50,000 parameters!\n",
    "\n",
    "Next we need to give the model:\n",
    "1. An optimizer strategy\n",
    "2. A way to calculate loss\n",
    "3. The metric evaluate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712fdc57",
   "metadata": {},
   "source": [
    "Lastly, we train the model using the `model_name.fit()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f703738",
   "metadata": {},
   "source": [
    "If you run the code below.... you would find that the model would fail to train. I do not suggest running it to save memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = first_network.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9fda6",
   "metadata": {},
   "source": [
    "Remember that half the battle with model training is understanding what format we need the data in!\n",
    "\n",
    "We won't go over this in too much detail, but in a snapshot we will:\n",
    "1. Flatten the pixel dimensions from (28,28) into a single dimension (784)\n",
    "2. Change pixel data type from integer with pixel values \\[0, 225\\] to a float values \\[0,1\\].\n",
    "3. Expand the y targets from a single dimension with values \\[0:9\\] to 10 dimensions each representing a target class. \n",
    "    - In each row, the target class column will have a value of 1, while the other columns will have a value of 0\n",
    "    - This is a common technique to reformat categorical targets known as [One Hot Encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(xdata, ydata):\n",
    "    \"\"\"\n",
    "    Transforms image data:\n",
    "        1. Flattens pixel dimensions from 2 -> 1\n",
    "        2. Scales pixel values between [0,1]\n",
    "    Transforms target data (ydata):\n",
    "        - Formats targets as one hot encoded columns\n",
    "    \"\"\"\n",
    "    \n",
    "    x = {}\n",
    "    for name, partition in zip([\"x_train\", \"x_val\", \"x_test\"],xdata):\n",
    "        flatten = partition.reshape((partition.shape[0], 28 * 28))\n",
    "        scaled = flatten.astype('float32') / 255\n",
    "        x[name] = scaled\n",
    "    \n",
    "    y = {}\n",
    "    for name, partition in zip([\"y_train\", \"y_val\", \"y_test\"],ydata):\n",
    "        y[name] = to_categorical(partition)\n",
    "    \n",
    "    return x['x_train'], y['y_train'], x['x_val'], y['y_val'], x['x_test'], y['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trans, y_train_trans, x_val_trans, y_val_trans, x_test_trans, y_test_trans = transform_data([x_train, x_val, x_test],\n",
    "                                                                                                    [y_train, y_val, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary([x_train_trans, y_train_trans, x_val_trans, y_val_trans, x_test_trans, y_test_trans])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e48488",
   "metadata": {},
   "source": [
    "We have succesfully flattened our input images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f845ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = first_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=5, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221b829",
   "metadata": {},
   "source": [
    "### Visualizing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_accuracy(history_dict):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy of a neural network.\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, color = 'navy', alpha = 0.8, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, color = 'green', label='Validation Accuracy')\n",
    "    plt.title('Training and validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ea650",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7b7e7",
   "metadata": {},
   "source": [
    "Not too shabby for a *tiny* neural network!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd5123",
   "metadata": {},
   "source": [
    "Let's build a second network that has more neurons in the hidden layer (previously: 64, now: 512) and see how effects our classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_network = Sequential()\n",
    "second_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "second_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b65e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_two = second_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=5, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_two.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e90cc7",
   "metadata": {},
   "source": [
    "How does adding more neurons effect our training and validation accuracy?\n",
    "\n",
    "Let's keep training this model for 10 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a718300",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_two_more_epochs = second_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=10, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_epoch_plot(history_dicts):\n",
    "    \"\"\"\n",
    "    Combines two history dictionaries for extended epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_history = {key: [] for key in history_dicts[0].keys()}\n",
    "    \n",
    "    for hist in history_dicts:\n",
    "        for key in combined_history.keys():\n",
    "            combined_history[key].extend(hist[key])\n",
    "    \n",
    "    return plot_epoch_accuracy(combined_history)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695900f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_epoch_plot([history_two.history, history_two_more_epochs.history])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866c866",
   "metadata": {},
   "source": [
    "Diagnosing our accuracy plot, it looks like even with more epochs, our model is *still* failing to generalize. \n",
    "\n",
    "The dunning kruger effect in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd093e",
   "metadata": {},
   "source": [
    "One solution is to give our add an additional hidden layer to extract more features from the data.\n",
    "\n",
    "Below we add a second dense layer with the same number of neurons as our first dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_network = Sequential()\n",
    "third_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "third_network.add(Dense(512, activation= \"relu\"))\n",
    "third_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e262e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_two_layers = third_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=10, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_two_layers.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae52cb",
   "metadata": {},
   "source": [
    "Our model is still failing to generalize and reach validation accuracy that approaches the training accuracy!\n",
    "\n",
    "One way we can prevent our model from overfitting to the training data is to add dropout in our hidden layers.\n",
    "\n",
    "### TLDR for Dropout\n",
    "Dropout makes our network a bit \"forgetful\" during training. We get to set a proportion of neurons the network will randomly \"forget\" or \"drop\", which we set as a probability in the `model.add(Dropout(probability_here))` function.\n",
    "\n",
    "This forces our model to generalize, preventing it from overfitting to the training data. \n",
    "\n",
    "Check out [Hinton et al. 2012](https://arxiv.org/abs/1207.0580) describing how dropout helps neural network generalization.\n",
    "- *Fun fact: they also use MNIST to test model generalization :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff735c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_network = Sequential()\n",
    "fourth_network.add(Dense(512, activation= \"relu\", input_shape=(28*28,)))\n",
    "fourth_network.add(Dropout(0.5))\n",
    "fourth_network.add(Dense(512, activation= \"relu\"))\n",
    "fourth_network.add(Dropout(0.5))\n",
    "fourth_network.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_network.compile(optimizer = 'rmsprop', \n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f366fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = fourth_network.fit(x_train_trans, \n",
    "                            y_train_trans, \n",
    "                            epochs=20, \n",
    "                            batch_size=128, \n",
    "                            validation_data=(x_val_trans, y_val_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63f132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_epoch_accuracy(history_dropout.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad25319",
   "metadata": {},
   "source": [
    "After implementing dropout, do you think the model is better able to generalize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a24c3b",
   "metadata": {},
   "source": [
    "## Challenge 2: Build your own neural network\n",
    "\n",
    "1. Build and compile your own neural network in an object called `my_network`. Feel free to choose your own:\n",
    "    - Architecture\n",
    "    - Activation Function\n",
    "    - Epochs\n",
    "    \n",
    "2. Train your model, saving the results to an object called `history_my_network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e16f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9a307c",
   "metadata": {},
   "source": [
    "Now that we have several models on hand, let's see how they perform on the holdout test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53264eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes a model and a test set of data.\n",
    "    Returns the accuracy.\n",
    "    \"\"\"\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    accuracy = round(score[1]*100, 1)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate([first_network, second_network, third_network]):\n",
    "    acc = get_model_accuracy(model, x_test_trans, y_test_trans)\n",
    "    print(f\"Model {i+1} has an accuracy of {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed1dea",
   "metadata": {},
   "source": [
    "## Challenge 3: Evaluate your own model\n",
    "\n",
    "Use your own model from challenge 2 to evaluate its general performance.\n",
    "\n",
    "1. Visualize the training and validation accuracy over each epoch.\n",
    "2. Print the accuracy of your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916e30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd1b345",
   "metadata": {},
   "source": [
    "### Visualize the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrong_predictions(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Plots 25 incorrectly predicted images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Back transform images\n",
    "    x_images = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "    \n",
    "    # Format predictions and targets\n",
    "    predictions = model.predict(x_test)\n",
    "    predicted = np.argmax(predictions, axis=1)\n",
    "    target = np.argmax(y_test, axis = 1)\n",
    "    \n",
    "    # Get wrong indices\n",
    "    wrong_indices = np.where(predicted != target)[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(5,5, figsize = (25,25))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for ax, index in zip(axes, wrong_indices[:26]):\n",
    "        ax.imshow(x_images[index], cmap=plt.cm.binary, interpolation='nearest')\n",
    "        ax.set_title(f\"Predicted {predicted[index]}, Actual is {target[index]}\", size = 20)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6513237",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wrong_predictions(fourth_network, x_test_trans, y_test_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819253a",
   "metadata": {},
   "source": [
    "Do you feel our model made reasonable mistakes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74bc1dc",
   "metadata": {},
   "source": [
    "### Saving our models\n",
    "\n",
    "Training models can be a lengthy and computationally resource-intensive task!\n",
    "\n",
    "After we train a model, we often want to save it to a file so we can use our trained weights in other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16935892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(models, filenames, path = os.path.join(\"..\", \"data\")):\n",
    "    \"\"\"\n",
    "    Takes a list of model objects and a path to store the models in.\n",
    "    Saves these models in the path location using the objectname.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle single inputs as one-element lists\n",
    "    if type(models) is not list:\n",
    "        models = [models]\n",
    "    if type(filenames) is not list:\n",
    "        filenames = [filenames]\n",
    "    \n",
    "    assert len(models) == len(filenames), f\"There is a mismatch in the number of models: {len(models)} and filenames: {len(filenames)}\"\n",
    "    \n",
    "    # If the folder to store models doesn't yet exist, make it\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    for model, file in zip(models, filenames):\n",
    "        # Make the full filepath\n",
    "        filepath = os.path.join(path, file)\n",
    "        \n",
    "        # Save the model to the filepath\n",
    "        model.save(filepath)\n",
    "        print(f\"Saved {file} to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db485e4",
   "metadata": {},
   "source": [
    "The neural networks we have created so far are known as *vanilla neural networks*. In the next notebook we will explore a different neural network architechture known as *convolutional neural networks*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models([first_network, second_network, third_network, fourth_network],\n",
    "            [\"first_nn\", \"second_nn\", \"third_nn\", \"fourth_nn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37968dfc",
   "metadata": {},
   "source": [
    "## Challenge 4: Save your own model\n",
    "\n",
    "Save your own model `my_network` in the same directory we saved our other models in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ad2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
